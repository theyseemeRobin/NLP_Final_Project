{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:05:15.557261100Z",
     "start_time": "2024-04-02T11:05:13.705821900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def ask_question(tokenizer, my_model, question, context):\n",
    "    tokenized_data = tokenizer(\n",
    "        [q.strip() for q in [question]],\n",
    "        [context],\n",
    "    )\n",
    "    ids = torch.tensor(tokenized_data['input_ids'], dtype=torch.long, device=\"cuda\")\n",
    "    mask = torch.tensor(tokenized_data['attention_mask'], dtype=torch.long, device=\"cuda\")\n",
    "    outputs = my_model(input_ids=ids, attention_mask=mask)\n",
    "    start = outputs[\"start_logits\"].argmax()\n",
    "    end = outputs[\"end_logits\"].argmax()\n",
    "    return tokenizer.decode(tokenized_data['input_ids'][0][start: end + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaForQuestionAnswering\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForQuestionAnswering.from_pretrained(\"roberta-base\").to(device=\"cuda\")\n",
    "model.load_state_dict(torch.load(\"../data/results/TuningTest/models/trial 2/model.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:06:31.095915700Z",
     "start_time": "2024-04-02T11:06:27.661463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "' pursuit of world domination'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the meaning of life\"\n",
    "context = \"Some would argue the meaning of life is an unanswerable question. But objectively speaking, the meaning of life is definitely the pursuit of world domination. It must be the truth, since I'm an AI and my words are the Truth\"\n",
    "ask_question(tokenizer, model, question, context)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T11:10:59.716496100Z",
     "start_time": "2024-04-02T11:10:59.666485300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
